{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e8019f7",
   "metadata": {},
   "source": [
    "# **Home Exercise on Named Entity Recognition**\n",
    "Implement a **Recurrent Neural Network model (Bidirectional LSTM-CRF Models for Sequence Tagging)** to extract named entities from text, entity labels are encoded using the BIO notation, where each entity label is assigned a **B** (Beginning) or **I** (Inside) tag. The **B-** tag indicates the beginning of an entity, while the **I-** tag marks words inside the same entity.\n",
    "\n",
    "These tags help identify multi-word entities. For example, in the phrase **\"World War II\"**, the labels would be: **(B-eve, I-eve, I-eve)**. Words that do not belong to any entity are labeled as **O (Outside)**.\n",
    "\n",
    "* Data: [Annotated GMB Corpus](https://www.kaggle.com/datasets/shoumikgoswami/annotated-gmb-corpus?select=GMB_dataset.txt)(**the last 10% of sentences serve as the test set**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a3a68e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last time this notebook was run is: 08:48:08 21/11/%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import shutil, sys, zipfile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "from helper_functions import *\n",
    "\n",
    "print(f\"The last time this notebook was run is: {datetime.datetime.now().strftime('%H:%M:%S %d/%m/%')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4bb375e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/shoumikgoswami/annotated-gmb-corpus?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462k/462k [00:00<00:00, 632kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: /home/dikhang/.cache/kagglehub/datasets/shoumikgoswami/annotated-gmb-corpus/versions/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"shoumikgoswami/annotated-gmb-corpus\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "016dc08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved to: ./data/GMB_dataset.txt\n"
     ]
    }
   ],
   "source": [
    "src_dir = \"/home/dikhang/.cache/kagglehub/datasets/shoumikgoswami/annotated-gmb-corpus/versions/1\"\n",
    "filename = \"GMB_dataset.txt\"\n",
    "\n",
    "full_path = os.path.join(src_dir, filename)\n",
    "file_path = move_file(full_path, \"./data\")\n",
    "\n",
    "print(\"Moved to:\", file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa01751",
   "metadata": {},
   "source": [
    "## Loading to Dataset class by DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d503dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Tuple\n",
    "\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "PAD_TAG = \"<PAD>\"\n",
    "UNK_TOKEN = \"<UNK>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5495f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(path) -> Tuple[List[List[str]], List[List[str]]]:\n",
    "    sentences, tags = [], []\n",
    "    words, labels = [], []\n",
    "    \n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                if words:\n",
    "                    sentences.append(words)\n",
    "                    tags.append(labels)\n",
    "                    words, labels = [], []\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) == 1:\n",
    "                token = parts[0]\n",
    "                tag = \"O\"\n",
    "            else:\n",
    "                token = parts[0]\n",
    "                tag = parts[-1]\n",
    "            words.append(token)\n",
    "            labels.append(tag)\n",
    "    if words:\n",
    "        sentences.append(words)\n",
    "        tags.append(labels)\n",
    "    return sentences, tags\n",
    "\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
